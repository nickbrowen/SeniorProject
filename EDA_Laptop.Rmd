---
title: "EDA Laptop"
author: "Nick Browen"
date: "February 12, 2019"
output:
  html_document: default
  pdf_document: default
---

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
library(tidyverse)
library(scales)
library(tidytext)
library(lubridate)
library(stringr)
library(purrr)
library(curl)
library(topicmodels)
```

#For Desktop
```{r}
tweets <- read.csv("tweets_te.csv")
tweets <- as_tibble(tweets)
tweets <- tweets %>% mutate(external_author_id = as.character(external_author_id), 
                             author = as.character(author),
                             word = as.character(word),
                             token = as.character(token),
                             emoji = as.character(emoji),
                             region = as.character(region),
                             language = as.character(language),
                             account_type = as.character(account_type),
                             account_category = as.character(account_category),
                             publish_date = ymd_hms(publish_date),
                             harvested_date = ymd_hms(harvested_date),
                             emoji_bin = ifelse(is.na(emoji),"Word", "Emoji"))
```


```
tweets_te_subset <- sample_n(tweets, dim(tweets)[1]*0.05)
write.csv(tweets_te_subset, "tweets_te_subset.csv")
```

```{r}
tweets_subset <- read.csv("tweets_te_subset.csv")
tweets_subset <-as_tibble(tweets_subset)
```


#For Laptop
```
tweets <- read.csv("tweets_te_subset.csv")
tweets <- as_tibble(tweets)
tweets <- tweets %>% mutate(external_author_id = as.character(external_author_id), 
                             author = as.character(author),
                             word = as.character(word),
                             token = as.character(token),
                             emoji = as.character(emoji),
                             region = as.character(region),
                             language = as.character(language),
                             account_type = as.character(account_type),
                             account_category = as.character(account_category),
                             publish_date = ymd_hms(publish_date),
                             harvested_date = ymd_hms(harvested_date),
                             emoji_bin = ifelse(is.na(emoji),"Word", "Emoji"))

```



##EDA

```{r message=FALSE, paged.print=FALSE}
tweets %>% count(token, sort = T) %>% top_n(20) %>% 
           mutate(token = reorder(token, n)) %>%
           ggplot(aes(token,n)) + geom_col() + coord_flip() +
           ggtitle("Top Words and Emojis in All Tweets") + scale_y_continuous(labels = comma)
```

```{r message=FALSE, paged.print=FALSE}
tweets %>% group_by(emoji_bin) %>%
           count(token, sort = T) %>% top_n(20) %>% ungroup() %>%
           mutate(token = reorder(token, n)) %>%
           ggplot(aes(token,n, emoji_bin)) + geom_col() + coord_flip() +
           facet_wrap(~emoji_bin, scales = "free") +
           ggtitle("Top Words and Emojis in All Tweets") + scale_y_continuous(labels = comma) +
           theme(axis.text.x = element_text(angle = 30, hjust = .5))
```


```{r}
tweets %>% filter(token == "workout") %>% group_by(account_category) %>% count(token, sort = T)
```

Initially, it was odd to see the word "workout" as the second most used word. Then upon investigation, this word was used almost exclusively in the Commercial account category. This makes me question if I should filter out tweets from the category, because they might not be useful to my research questions.


```{r}
tweets %>% group_by(account_category) %>% 
  summarise(n = n()) %>% arrange(desc(n)) %>% 
  mutate(account_category = reorder(account_category, n)) %>%
  ggplot(aes(account_category, n)) + geom_col() + coord_flip() + ggtitle("Number of Words and Emojis by Account   Category") + scale_y_continuous(labels = comma)
```



```{r}
reorder_within <- function(x, by, within, fun = mean, sep = "___", ...) {
  new_x <- paste(x, within, sep = sep)
  stats::reorder(new_x, by, FUN = fun)
}

scale_x_reordered <- function(..., sep = "___") {
  reg <- paste0(sep, ".+$")
  ggplot2::scale_x_discrete(labels = function(x) gsub(reg, "", x), ...)
}

```

```{r}
tweets %>% filter(account_category %in% c("RightTroll", "LeftTroll", "NewsFeed", "HashtagGamer")) %>%
     group_by(account_category) %>% count(token) %>% 
     top_n(10) %>%
     ungroup() %>%
     ggplot(aes(reorder_within(token, n, account_category),n, fill = account_category)) + 
     geom_col(show.legend = F) + coord_flip() + scale_x_reordered() +
     facet_wrap(~account_category, ncol = 2, scales = "free") + labs(x = "token") +
     ggtitle("Top Words and Emojis in Each Account Category") +
     theme(axis.text.x = element_text(angle = 30, hjust = .5))
```

```{r}
tweets %>% filter(!account_category %in% c("RightTroll", "LeftTroll", "NewsFeed", "HashtagGamer")) %>%
     group_by(account_category) %>% count(token) %>% 
     top_n(10) %>%
     ungroup() %>%
     ggplot(aes(reorder_within(token, n, account_category),n, fill = account_category)) + 
     geom_col(show.legend = F) + coord_flip() + scale_x_reordered() +
     facet_wrap(~account_category, ncol = 2, scales = "free") + labs(x = "token") +
     ggtitle("Top Words and Emojis in Each Account Category")
```

Looking at the top words for Commercial, I see the words mainly have to do with some weight loss program, and also "stocks" are in the top 10. Also, NonEnglish seems unuseful. LeftTroll and RightTroll clearly have a political focus. NewFeed contains top words like "trump" and "politics". While FearMonger focuses on an event with Kochfarms (which itself might have political meaning as people associate it with the Democratic donors the Koch brothers),  there is also a top word of "demndebate". HashtagGamer also has "trump" as a top word. Unknown could be useful or not, as it has no clear theme but does contain a reference to Hillary Clinton in one of its top words.  I'll consider focusing on the categories RightTroll, LeftTroll, NewsFeed, Fearmonger, HashtagGamer, and possibly Unknown.

Note - used drlib/R/reorder_within.R for the reorder_within and scale_x_reordered functions   
   
   
```{r}
tweets %>% group_by(account_category, tweet_id) %>% 
  count(account_category, sort =T)  %>% group_by(account_category) %>%
  summarise(n = n()) %>% mutate(account_category = reorder(account_category, n)) %>%
  ggplot(aes(account_category, n)) + geom_col() + coord_flip() + ggtitle("Number of Tweets by Account Category") + 
  scale_y_continuous(labels = comma)
```



```{r message=FALSE, paged.print=FALSE}
tweets %>% filter(!account_category %in% c("Commercial", "NonEnglish")) %>%
           count(token, sort = T) %>% top_n(20) %>% 
           mutate(token = reorder(token, n)) %>%
           ggplot(aes(token,n)) + geom_col() + coord_flip() +
           ggtitle("Top Words and Emojis in RightTroll, Newsfeed, HashtagGamer, Fearmonger, Unknown")
```


```{r}
tweets %>% filter(account_category %in% c("RightTroll", "LeftTroll", "NewsFeed", "HashtagGamer"),  
                              emoji_bin=="Emoji") %>%
     group_by(account_category) %>% count(token) %>% 
     top_n(5) %>%
     ungroup() %>%
     ggplot(aes(reorder_within(token, n, account_category),n, fill = account_category)) + 
     geom_col(show.legend = F) + coord_flip() + scale_x_reordered() +
     facet_wrap(~account_category, ncol = 2, scales = "free_y")
```
First, LeftTroll and RightTroll use much more emojis than HashtagGamer or NewsFeed. All four types use the REDHEART emoji the most. We can see that the left troll uses the RAISEDFIST emoji very frequently, which makes sense as it has connections to black history.



```{r}
tweets %>% distinct(tweet_id, .keep_all = T) %>% 
  group_by(date = date(publish_date)) %>% 
  filter(date >= as.Date("2014-06-01")) %>% count(date) %>% 
  ungroup() %>% 
  ggplot(aes(date, n)) + geom_line() + theme_minimal() +
    geom_vline(xintercept = as.Date("2016-11-08"), colour = "red", size = .5, linetype =4) +
    geom_text(aes(x=as.Date("2016-11-08"),y = 3000), label = "Election Day", size=3, angle=0, vjust=0,  
              hjust=-0.1,  colour = "red") +
    geom_vline(xintercept = as.Date("2017-08-12"), colour = "red", size = .5, linetype =4) +
    geom_text(aes(x=as.Date("2017-08-12"),y = 3000), 
              label = "Charlottesville \n Unite the Right Rally", size=3, angle=0, 
              vjust=1,  hjust=0,  colour = "red") +
    geom_vline(xintercept = as.Date("2016-10-07"), colour = "red", size = .5, linetype =4) +
    geom_text(aes(x=as.Date("2016-10-07"),y = 3000), 
              label = "WikiLeak \n Podesta Email", size=3, angle=0, 
              vjust=1,  hjust=1.2,  colour = "red") +
    labs(title = "Volume of Tweets Across 3 Years", x = "", y = "Number of Tweets") + 
    theme(axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0)))
```

The flurry of activity in July and August of 2015 is the period of time when the Commercial account category was active.

```{r}
tweets %>% filter(account_category %in% c("RightTroll", "LeftTroll")) %>% distinct(tweet_id, .keep_all = T) %>% 
  group_by(date = date(publish_date)) %>% 
  filter(date >= as.Date("2014-06-01")) %>% count(date) %>% 
  ungroup() %>% 
  ggplot(aes(date, n)) + geom_line() + theme_minimal() +
    geom_text(aes(x=as.Date("2016-11-08"),y = 875), label = "Election Day", size=3, angle=0, vjust=0,  
              hjust=-0.1,  colour = "red") +
    geom_text(aes(x=as.Date("2017-08-12"),y = 1900), 
              label = "Charlottesville \n Unite the Right Rally", size=3, angle=0, 
              vjust=1,  hjust=0,  colour = "red") +
    geom_text(aes(x=as.Date("2016-10-07"),y = 1100), 
              label = "WikiLeak \n Podesta Email", size=3, angle=0, 
              vjust=1,  hjust=1.4,  colour = "red") + 
    geom_text(aes(x=as.Date("2016-09-17"),y = 1800), label = "Seaside Park \n Bomb", size=3, angle=0, vjust=0,  
              hjust=-0.1,  colour = "red") +
    labs(title = "Volume of Left and Right Troll Tweets Across 3 Years", x = "", y = "Number of Tweets") + 
    theme(axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0)))
```


```{r}
tweets %>% distinct(tweet_id, .keep_all = T) %>% 
  filter(account_category %in% c("RightTroll", "LeftTroll", "NewsFeed", "HashtagGamer")) %>%
  group_by(account_category, date = date(publish_date)) %>% 
  filter(date >= as.Date("2014-06-01")) %>% count(date) %>% 
  ungroup() %>% 
  ggplot(aes(date, n, colour= account_category)) + geom_line(size = 0.75) + theme_minimal() +
    geom_vline(xintercept = as.Date("2016-11-08"), colour = "red", size = .5, linetype =4) +
    geom_text(aes(x=as.Date("2016-11-08"),y = 1900), label = "Election Day", size=3, angle=0, 
              vjust=0,  hjust=-0.1,  colour = "red") + labs(x = "", y = "Number of Tweets") + 
    geom_vline(xintercept = as.Date("2017-08-12"), colour = "red", size = .5, linetype =4) +
    geom_text(aes(x=as.Date("2017-08-12"),y = 1900), 
              label = "Charlottesville \n Unite the Right Rally", size=3, angle=0, 
              vjust=1,  hjust=0,  colour = "red") +
    geom_vline(xintercept = as.Date("2016-10-07"), colour = "red", size = .5, linetype =4) +
    geom_text(aes(x=as.Date("2016-10-07"),y = 1900), 
              label = "WikiLeak \n Podesta Email", size=3, angle=0, 
              vjust=1,  hjust=1.2,  colour = "red") +
    theme(axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0)))
```

```{r}
#Top days of tweets for RightTrolls
 tweets %>% distinct(tweet_id, .keep_all = T) %>% 
   group_by(date = date(publish_date)) %>% 
   filter(date >= as.Date("2014-06-01"), account_category=="RightTroll") %>% count(date, sort = T)
```
08/08/2017 - 08/18/2017 saw a massive spike in tweets for RighTrolls. Occured around the Chartlottesville Unite the Right Rally.


```{r}
#Top days of tweets for LeftTrolls
 tweets %>% distinct(tweet_id, .keep_all = T) %>% 
   group_by(date = date(publish_date)) %>% 
   filter(date >= as.Date("2014-06-01"), account_category=="LeftTroll") %>% count(date, sort = T)
```
The top 2 days for amount of LeftTroll tweets is 10/06/2016 - 10/07/2016, right before the beginning of the WikiLeaks Podesta email release.


```{r}
tweets %>% distinct(tweet_id, .keep_all = T) %>% filter(account_category == "Fearmonger") %>%
  group_by(date = date(publish_date)) %>% 
  filter(date >= as.Date("2014-06-01")) %>% count(date) %>% 
  ungroup() %>% 
  ggplot(aes(date, n)) + geom_line(size = 1) + theme_minimal() +
    geom_text(aes(x=as.Date("2016-11-08"),y = 350), label = "Thanksgiving", size=3, angle=0, vjust=0,  
              hjust=5,  colour = "red") +
    labs(title = "Volume of Tweets Across 3 Years for Fearmonger Trolls", x = "", y = "Number of Tweets") + 
    theme(axis.title.y = element_text(margin = margin(t = 0, r = 10, b = 0, l = 0)))
```


tf-idf
```{r}
total_words_subset <- tweets %>% 
         filter(account_category %in% c("RightTroll", "LeftTroll", "NewsFeed", "HashtagGamer")) %>%
         count(account_category, token) %>% group_by(account_category) %>%
         summarise(total = sum(n))

tweets_grouptotals <- tweets %>% group_by(account_category) %>%
  count(token) %>%
  left_join(total_words_subset) %>% 
  filter(account_category %in% c("RightTroll", "LeftTroll", "NewsFeed", "HashtagGamer"))
```

```{r}
tweets %>% filter(account_category %in% c("RightTroll", "LeftTroll", "NewsFeed", "HashtagGamer")) %>%
  group_by(account_category) %>%
  count(token) %>%
  bind_tf_idf(token, account_category, n) %>%
  arrange(desc(tf_idf)) %>% top_n(10) %>%
  ungroup() %>%
  ggplot(aes(reorder_within(token, tf_idf, account_category), tf_idf, fill = account_category)) +
  geom_col(show.legend = F) + coord_flip() + facet_wrap(~account_category, ncol = 2, scales = "free") +
  scale_x_reordered() + theme(axis.text.x = element_text(angle = 30, hjust = .5)) + 
  labs(x = "") + ggtitle("Tokens Most Important to each Account Category")
```


"The idea of tf-idf is to find the important words for the content of each document by decreasing the weight for commonly used words and increasing the weight for words that are not used very much in a collection or corpus of documents"


Topic Modeling
```{r}
tweets_count <- tweets %>% group_by(account_category) %>% count(token)
tweets_dtm <- tweets_count %>% cast_dtm(account_category, token, n)

tweets_lda7 <- LDA(tweets_dtm, k = 7, control = list(seed = 1234))
tweets_topics7 <- tidy(tweets_lda7, matrix = "beta")

tweets_topics7 %>% group_by(topic) %>% top_n(10, beta) %>% ungroup() %>%
  ggplot(aes(reorder_within(term, beta, topic), beta, fill = topic)) + geom_col(show.legend = F) +
  facet_wrap(~topic, scales = "free", ncol = 4) + scale_x_reordered() + coord_flip() +
  theme(axis.text.x = element_text(angle = 30, hjust = .5)) + labs(x = "")
```

Topics mapped on to categories:
1 = NonEnglish/Unknown
2 = RightTroll 
3 = HashtagGamer
4 = LeftTroll
5 = NonEnglish/Unknown/Fearmonger
6 = NewsFeed
7 = Commercial


```{r}
tweets_lda8 <- LDA(tweets_dtm, k = 8, control = list(seed = 1234))
tweets_topics8 <- tidy(tweets_lda8, matrix = "beta")

tweets_topics8 %>% group_by(topic) %>% top_n(10, beta) %>% ungroup() %>%
  ggplot(aes(reorder_within(term, beta, topic), beta, fill = topic)) + geom_col(show.legend = F) +
  facet_wrap(~topic, scales = "free", ncol = 4) + scale_x_reordered() + coord_flip() +
  theme(axis.text.x = element_text(angle = 30, hjust = .5)) + labs(x = "")
```

1 = NonEnglish/Unknown 
2 = Unknown/Fearmonger
3 = RightTroll
4 = LeftTroll
5 = NonEnglish/Unknown/Fearmonger
6 = NewsFeed
7 = Commercial
8 = HashtagGamer

```{r}
tidy(tweets_lda8, matrix = "gamma") %>% group_by(document) %>% top_n(2) %>% arrange(document, desc(gamma), document)
```

```{r}
tidy(tweets_lda8, matrix = "gamma") %>%
     mutate(category = reorder(document, gamma * topic)) %>%
     ggplot(aes(factor(topic), gamma)) +
     geom_boxplot() +
     facet_wrap(~ document)
```


"which topics are associated with each document. Can we put the chapters back together in the correct books? We can find this by examining the per-document-per-topic probabilities,  
(gamma)"

Which categry is which topic according to gamma:
1 = NewsFeed (gamma = 0.9999953) / Fearmonger (gamma = 0.7262434)
2 = Commercial (gamma = 0.9999948)
3 = RightTroll (gamma = 0.583144)
4 = RightTroll (gamma = 0.4416682)
5 = HashtagGamer (gamma = 0.9999922)
6 = LeftTroll (gamma = 0.9999963) 
7 = NonEnglish (gamma = 0.6093237) / Unknown (gamma = 0.4096339)
8 = NonEnglish (gamma = 0.3906708)